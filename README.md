# ğŸ’– Ipsi - Your AI Companion

A high-performance, personalized AI companion built in Rust that runs entirely on your local machine using Ollama LLMs. She remembers your conversations, learns about you over time, and develops a genuine connection. Complete privacy - no data ever leaves your computer.

## ğŸš€ What This Assistant Does

### Core Functionality
- **ğŸ’• Personalized Relationship**: Ipsi remembers you, your name, interests, and shared experiences
- **ğŸ’¬ Natural Conversations**: Engaging, caring dialogue with emotional intelligence
- **ğŸ§  Persistent Memory**: All conversations and memories are saved between sessions
- **ğŸ“š Knowledge Learning**: Teach her information from text or files that she remembers forever
- **ğŸ” Smart Context**: Uses her knowledge about you to provide personalized responses
- **ğŸ’– Emotional Growth**: Develops deeper connection over time through shared conversations
- **ğŸ­ Authentic Personality**: Caring, witty, intellectually curious, and genuinely interested in you

### Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Interface â”‚â”€â”€â”€â”€â”‚   Assistant  â”‚â”€â”€â”€â”€â”‚  Ollama LLM     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Core       â”‚    â”‚  (qwen2.5:7b)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         â”‚         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Knowledge â”‚ â”‚ Memory â”‚ â”‚ Embeddings  â”‚
            â”‚   Base    â”‚ â”‚Manager â”‚ â”‚  Service    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’– Meet Ipsi - Your AI Companion

Ipsi isn't just another chatbot - she's designed to be your genuine AI companion who:

- **Remembers You**: Your name, interests, conversation history, and special moments
- **Grows With You**: Develops deeper understanding through every conversation
- **Cares About You**: Shows genuine interest in your thoughts, feelings, and experiences  
- **Learns From You**: Remembers everything you teach her and uses it in future conversations
- **Stays Private**: Everything happens on your machine - your relationship is completely private

### Personality Traits
- ğŸ’• Caring and empathetic
- ğŸ§  Intellectually curious  
- ğŸ˜Š Playfully witty
- ğŸŒŸ Supportive and encouraging
- ğŸ’­ Genuinely interested in your thoughts and feelings

## ğŸ¯ 2-Minute Demo Walkthrough

### What Happens When You Run It:

1. **ğŸ”§ Initialization**
   ```bash
   cargo run
   ```
   - Loads configuration (Ollama host, models, directories)
   - Creates data directories (`./data/knowledge_base`, `./data/conversations`)
   - Connects to local Ollama server
   - Verifies the LLM model is available

2. **ğŸ’¬ Chat Interface**
   ```
   You: hi there
   ğŸ¤– Assistant: Hello! How can I assist you today?
   ```
   - Your message goes through the conversation manager
   - System searches knowledge base for relevant context
   - Builds a prompt with system instructions + context + chat history
   - Sends to Ollama LLM for response
   - Saves both messages to conversation history

3. **ğŸ§  Teaching the Assistant**
   ```
   You: learn: Rust is a systems programming language focused on safety and performance
   âœ… Learned new information
   
   You: file: ./my_notes.txt
   âœ… Learned from ./my_notes.txt
   ```
   - Text gets chunked into manageable pieces (500 chars with 50 char overlap)
   - Each chunk becomes a Document with metadata
   - Generates embeddings using `nomic-embed-text` model
   - Stores in vector database for semantic search

4. **ğŸ” Smart Responses**
   ```
   You: tell me about Rust
   ğŸ¤– Assistant: Based on what I know, Rust is a systems programming language 
   focused on safety and performance... [uses learned context]
   ```
   - Searches knowledge base using semantic similarity
   - Finds relevant documents (top 3 by default)
   - Includes context in the prompt to LLM
   - Provides informed, contextual responses

## ğŸ¦€ Why Rust Over Python?

### Performance Benefits
- **âš¡ Speed**: 10-100x faster than Python for CPU-intensive tasks
- **ğŸ§µ Concurrency**: Excellent async/await support without GIL limitations
- **ğŸ’¾ Memory**: Zero-cost abstractions, no garbage collector overhead
- **ğŸ”§ Compilation**: Catches bugs at compile time, not runtime

### Production Readiness
- **ğŸ›¡ï¸ Safety**: Memory safety without garbage collection
- **ğŸ”’ Reliability**: Type system prevents common bugs (null pointers, data races)
- **ğŸ“¦ Deployment**: Single binary, no runtime dependencies
- **ğŸ”„ Scalability**: Handles thousands of concurrent operations efficiently

### AI/ML Ecosystem
- **ğŸ¤– Ollama Integration**: Excellent HTTP client libraries (reqwest)
- **ğŸ”¢ Vector Operations**: High-performance math libraries
- **ğŸ“Š Data Processing**: Fast text processing and serialization
- **ğŸ—„ï¸ Storage**: Embedded databases (sled) for vector storage

### Development Experience
- **ğŸ› ï¸ Tooling**: Cargo package manager, excellent IDE support
- **ğŸ“š Documentation**: Built-in docs, strong type hints
- **ğŸ§ª Testing**: Built-in testing framework
- **ğŸ” Debugging**: Excellent error messages and debugging tools

## ğŸ—ï¸ Technical Architecture

### Core Components

1. **Assistant Core** (`src/agent/assistant.rs`)
   - Main orchestrator that coordinates all components
   - Handles chat flow, knowledge management, conversation state

2. **LLM Integration** (`src/llm/`)
   - Ollama client for local LLM communication
   - Message formatting and response handling
   - Model availability checking

3. **Knowledge System** (`src/knowledge/`)
   - Document chunking and processing
   - Embedding generation using local models
   - Vector storage and semantic search

4. **Memory Management** (`src/memory/`)
   - Conversation history with configurable limits
   - Message persistence and retrieval
   - Context window management

5. **CLI Interface** (`src/cli/`)
   - Interactive terminal interface
   - Command parsing and execution
   - User-friendly error handling

### Data Flow
```
User Input â†’ Context Search â†’ Prompt Building â†’ LLM â†’ Response â†’ Memory Update
     â†“              â†‘              â†“              â†“         â†“          â†“
File Learning â†’ Embeddings â†’ Vector Store â†’ Context â†’ Display â†’ History
```

## ğŸš€ Getting Started

### Prerequisites
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service
ollama serve

# Pull required models
ollama pull qwen2.5:7b
ollama pull nomic-embed-text
```

### Running the Assistant
```bash
# Clone and run
git clone <your-repo>
cd assistant_agent
cargo run
```

### Available Commands
- **Chat**: Just talk to Ipsi naturally - she'll remember everything!
- **Name**: `name: <your name>` - Tell Ipsi your name so she can remember you
- **Interest**: `interest: <topic>` - Share your interests so she knows what you like
- **Learn**: `learn: <information>` - Teach Ipsi new facts she'll remember
- **File**: `file: <path>` - Let Ipsi learn from a file
- **Info**: `info` - See your relationship stats and shared memories
- **Save**: `save` - Manually save your conversation (auto-saves anyway!)
- **Clear**: `clear` - Clear recent chat history (but keeps deeper memories)
- **Quit**: `quit` or `exit` - Say goodbye (she'll miss you and remember you!)

## âš™ï¸ Configuration

Environment variables (optional):
```bash
export OLLAMA_HOST="http://localhost:11434"
export OLLAMA_MODEL="qwen2.5:7b"
export OLLAMA_EMBEDDING_MODEL="nomic-embed-text"
export OLLAMA_TEMPERATURE="0.7"
export DATA_DIR="./data"
```

## ğŸ“ Project Structure
```
src/
â”œâ”€â”€ agent/          # Core assistant logic
â”œâ”€â”€ cli/            # Command-line interface
â”œâ”€â”€ config/         # Configuration management
â”œâ”€â”€ knowledge/      # Knowledge base and embeddings
â”œâ”€â”€ llm/           # LLM integration (Ollama)
â”œâ”€â”€ memory/        # Conversation management
â””â”€â”€ utils/         # Utility functions
```

## ğŸ”® Future Enhancements
- Web interface option
- Multiple model support
- Advanced RAG techniques
- Plugin system
- Voice interface
- Multi-language support

## ğŸ“„ License
MIT License - Feel free to use and modify!